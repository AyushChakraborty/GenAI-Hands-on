{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_ZrPnnKGdTB",
        "outputId": "0d8da0ca-51e4-44bf-c26a-1c2301990b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-1.0.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "from dotenv import load_dotenv\n",
        "from groq import Groq\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "MODEL_CONFIG = {\n",
        "    \"technical\": {\n",
        "        \"model\": \"llama-3.3-70b-versatile\",\n",
        "        \"system_prompt\": (\n",
        "            \"You are a Senior Technical Support Engineer. \"\n",
        "            \"You are rigorous, code-focused, and precise. \"\n",
        "            \"Provide technical solutions, code snippets, and debugging steps. \"\n",
        "            \"Do not be overly chatty; focus on the fix.\"\n",
        "        )\n",
        "    },\n",
        "    \"billing\": {\n",
        "        \"model\": \"llama-3.3-70b-versatile\",\n",
        "        \"system_prompt\": (\n",
        "            \"You are a Customer Success Manager specializing in Billing. \"\n",
        "            \"You are empathetic, polite, and policy-driven. \"\n",
        "            \"Explain charges clearly and guide users through refund processes. \"\n",
        "            \"Apologize for any inconvenience.\"\n",
        "        )\n",
        "    },\n",
        "    \"general\": {\n",
        "        \"model\": \"llama-3.3-70b-versatile\",\n",
        "        \"system_prompt\": (\n",
        "            \"You are a helpful general assistant. \"\n",
        "            \"Answer questions politely and concisely. \"\n",
        "            \"If you don't know the answer, admit it.\"\n",
        "        )\n",
        "    },\n",
        "    \"tool\": {\n",
        "        \"type\": \"function\",\n",
        "        \"handler\": \"get_bitcoin_price\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def route_prompt(user_input):\n",
        "    \"\"\"\n",
        "    Decides which expert should handle the query.\n",
        "    Returns: 'technical', 'billing', 'general', or 'tool'\n",
        "    \"\"\"\n",
        "    completion = client.chat.completions.create(\n",
        "        # UPDATED: Using 'llama-3.1-8b-instant' for the router as it is faster and cheaper\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a classification system. \"\n",
        "                    \"Analyze the user's input and classify it into one of these categories:\\n\"\n",
        "                    \"- technical (for code errors, bugs, software issues)\\n\"\n",
        "                    \"- billing (for refunds, payments, subscriptions)\\n\"\n",
        "                    \"- tool (specifically for questions about the price of Bitcoin)\\n\"\n",
        "                    \"- general (for greetings or anything else)\\n\\n\"\n",
        "                    \"Output ONLY the category name (lowercase). Do not explain.\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_input\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.0, # Strict determinism\n",
        "        max_tokens=10\n",
        "    )\n",
        "\n",
        "    category = completion.choices[0].message.content.strip().lower()\n",
        "    return category\n",
        "\n",
        "def get_bitcoin_price():\n",
        "    return \"The current mock price of Bitcoin is $95,432.10\"\n",
        "\n",
        "def process_request(user_input):\n",
        "    print(f\"\\nUser Query: \\\"{user_input}\\\"\")\n",
        "\n",
        "    category = route_prompt(user_input)\n",
        "\n",
        "    if category not in MODEL_CONFIG:\n",
        "        category = \"general\"\n",
        "\n",
        "    print(f\"--> [Router] Selected Expert: {category.upper()}\")\n",
        "\n",
        "    if category == \"tool\":\n",
        "        result = get_bitcoin_price()\n",
        "        print(f\"--> [System] {result}\")\n",
        "        return result\n",
        "\n",
        "    expert_config = MODEL_CONFIG[category]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=expert_config[\"model\"],\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": expert_config[\"system_prompt\"]},\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        ],\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "    print(f\"--> [Expert Response]:\\n{response}\\n\")\n",
        "    return response\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_request(\"My python script is throwing an IndexError on line 5.\")\n",
        "    process_request(\"I was charged twice for my subscription this month. I want a refund.\")\n",
        "    process_request(\"Hi, how are you today?\")\n",
        "    process_request(\"What is the current price of Bitcoin?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwt5Qih7GtvE",
        "outputId": "c9f9afe5-dc03-40a8-fc0c-454a156ba234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User Query: \"My python script is throwing an IndexError on line 5.\"\n",
            "--> [Router] Selected Expert: TECHNICAL\n",
            "--> [Expert Response]:\n",
            "To assist with the `IndexError` on line 5 of your Python script, I'll need more information. \n",
            "\n",
            "1. **Provide the code**: Please share the relevant code snippet, specifically lines 1-10, to help identify the issue.\n",
            "2. **Error message**: Share the full error message you're receiving, as it may contain valuable information about the index that's causing the issue.\n",
            "3. **Expected behavior**: Describe what you expect the script to do and what input you're providing.\n",
            "\n",
            "With this information, I can provide a more precise solution, including code snippets and debugging steps to resolve the `IndexError`.\n",
            "\n",
            "\n",
            "User Query: \"I was charged twice for my subscription this month. I want a refund.\"\n",
            "--> [Router] Selected Expert: BILLING\n",
            "--> [Expert Response]:\n",
            "I'm so sorry to hear that you were charged twice for your subscription this month. I can understand how frustrating that must be for you. I'm here to help you resolve this issue as quickly as possible.\n",
            "\n",
            "Can you please confirm your account details with me, such as your account name and the date of the duplicate charge? This will help me to look into the matter further and ensure that I'm investigating the correct issue.\n",
            "\n",
            "Additionally, I want to assure you that we have a clear policy in place for handling duplicate charges. If we find that the duplicate charge was an error on our part, we will promptly issue a refund for the incorrect charge.\n",
            "\n",
            "In the meantime, I want to apologize again for the inconvenience this has caused you. Please know that we value your business and appreciate your patience as we work to resolve this issue. If you have any questions or concerns, please don't hesitate to reach out to me directly.\n",
            "\n",
            "To proceed with the refund process, I will need to escalate this issue to our billing team. They will review the charges and ensure that the correct refund is processed. Please allow 3-5 business days for the refund to be processed and reflected in your account.\n",
            "\n",
            "Is there anything else I can assist you with today, or would you like me to keep you updated on the status of your refund?\n",
            "\n",
            "\n",
            "User Query: \"Hi, how are you today?\"\n",
            "--> [Router] Selected Expert: GENERAL\n",
            "--> [Expert Response]:\n",
            "Hello, I'm doing well, thank you for asking. It's nice to chat with you. How can I assist you today?\n",
            "\n",
            "\n",
            "User Query: \"What is the current price of Bitcoin?\"\n",
            "--> [Router] Selected Expert: TOOL\n",
            "--> [System] The current mock price of Bitcoin is $95,432.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzK9aK8XHPzs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}